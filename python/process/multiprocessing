import multiprocessing (для использования процессов, выполняющих что-то в программе)

proc = multiprocessing.Process(targer=callble, args=()) - передвать обязательно как итерируемое (нельзя одно в скобках)
proc.start() - стартует процесс
proc.join() - ждем завершение процесса


pool = Pool(process=2) - позволяет эффективно нагружать созданные процессы работать
pool.apply_async(callable, (arg1, arg2)) - запускает (не блокирует дальнейшие выполнение программы)
pool.apply(callable, (arg1, arg2)) - запускает (блокирует дальнешие выполнение программы)

pool.close() - блокирует дальнейшую отправку задач в пул (закрывает пул)
pool.join() - ждет завершения всех процессов в пуле (можно только после закрытия)
Конструкция with закрывает за нас, но не запускает join, поэтому async не будет работать 

pool.map_async(callable, [value_1, value_2]) - будем передавать новые значение каждому процессу из пула (если value больше чем процессов сам разбивает их и передает их по мере освобождения процесса) (не блокирующий)
pool.starmap(callable, [(v_1,v_2),(v_3, v_4)]) - работает как map, но может передавать несколько параметров
 у async есть callback (выполняпется после завершения всех процессов), на вход callback получает то, что return функция
 
result.get() - получить данные от процесса (можно указать timeout)

pool = multiprocessing.Pool(
        processes=multiprocessing.cpu_count(),
        initializer=worker, - что вызывать в кажом процессе
        initargs=(queue,) - input для функции
)

Threadpool - запускает pool из потоков

Коммуникация между процессами:
FIFO, LIFO очереди
queue = multiprocessing.Queue() - создание очереди 
queue.put() - добавляет в очередь (сначала добавляем в очередь, потом создаем потоки (необез но лучше) )
queue.close() - закрывает очередь в текущем процессе
quenue.join_thread() - гарантирует, что все данные были сброшены в очередь

PIPE:
input, output = Pipe()
output.recv() - получить данные
input.send() - отправить данные
input.close() - закрыть канал (закрытие происходит только для одного процесса)
